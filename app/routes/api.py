from flask import Blueprint, request, jsonify, session
from app.services.data_provider import DataProvider
from app.services.ai_analyzer import AIAnalyzer
from app.models.analysis import AnalysisLog, StockTradeSignal, RecommendationCache, User, Task, Portfolio, Transaction, Account, CashFlow
from app.services.model_config import get_models_for_frontend
from app.services.task_service import task_service
from app.services.email_validator import email_validator
from app import db
import json
import hashlib
import re
import uuid
import math
import pandas as pd
from datetime import datetime, timedelta

api_bp = Blueprint('api', __name__)
ai_analyzer = AIAnalyzer()


@api_bp.route('/health', methods=['GET'])
def health_check():
    """Lightweight health check endpoint to keep the service alive"""
    return jsonify({'status': 'ok', 'timestamp': datetime.utcnow().isoformat()}), 200

def update_cash_balance(user_id, currency, amount, transaction_type, trade_date, notes=''):
    """
    æ›´æ–°ç°é‡‘ä½™é¢
    :param user_id: ç”¨æˆ·ID
    :param currency: å¸ç§
    :param amount: é‡‘é¢ï¼ˆæ­£æ•°ï¼‰
    :param transaction_type: 'BUY' è¡¨ç¤ºå…¥é‡‘ï¼Œ'SELL' è¡¨ç¤ºå‡ºé‡‘
    :param trade_date: äº¤æ˜“æ—¥æœŸ
    :param notes: å¤‡æ³¨
    :return: æ˜¯å¦æˆåŠŸ
    """
    # æŸ¥æ‰¾æˆ–åˆ›å»ºç°é‡‘æŒä»“
    cash_portfolio = Portfolio.query.filter_by(
        user_id=user_id,
        symbol='CASH',
        asset_type='CASH',
        currency=currency
    ).first()
    
    if not cash_portfolio:
        # åˆ›å»ºç°é‡‘æŒä»“
        cash_portfolio = Portfolio(
            user_id=user_id,
            symbol='CASH',
            asset_type='CASH',
            currency=currency,
            total_quantity=0,
            avg_cost=1,  # ç°é‡‘æˆæœ¬å›ºå®šä¸º1
            total_cost=0
        )
        db.session.add(cash_portfolio)
        db.session.flush()
    
    # æ£€æŸ¥ä½™é¢æ˜¯å¦è¶³å¤Ÿï¼ˆå‡ºé‡‘æ—¶ï¼‰
    if transaction_type == 'SELL' and cash_portfolio.total_quantity < amount:
        return False, f'ç°é‡‘ä½™é¢ä¸è¶³ï¼Œå½“å‰ä½™é¢: {cash_portfolio.total_quantity:.2f}'
    
    # æ›´æ–°ç°é‡‘æŒä»“
    if transaction_type == 'BUY':
        # å…¥é‡‘
        cash_portfolio.total_quantity += amount
        cash_portfolio.total_cost += amount
    else:
        # å‡ºé‡‘
        cash_portfolio.total_quantity -= amount
        cash_portfolio.total_cost -= amount
    
    # åˆ›å»ºç°é‡‘äº¤æ˜“è®°å½•
    cash_transaction = Transaction(
        portfolio_id=cash_portfolio.id,
        user_id=user_id,
        transaction_type=transaction_type,
        trade_date=trade_date,
        price=1,  # ç°é‡‘ä»·æ ¼å›ºå®šä¸º1
        quantity=amount,
        amount=amount,
        notes=notes,
        source='auto'  # æ ‡è®°ä¸ºè‡ªåŠ¨ç”Ÿæˆ
    )
    db.session.add(cash_transaction)
    
    return True, 'success'

def get_or_create_account(user_id, currency):
    """
    è·å–æˆ–åˆ›å»ºè´¦æˆ·ï¼ˆå¤„ç†å¹¶å‘åˆ›å»ºçš„å”¯ä¸€çº¦æŸå†²çªï¼‰
    :param user_id: ç”¨æˆ·ID
    :param currency: å¸ç§
    :return: Accountå¯¹è±¡ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    # å…ˆå°è¯•æŸ¥è¯¢
    account = Account.query.filter_by(user_id=user_id, currency=currency).first()
    if account:
        return account
    
    # å¦‚æœä¸å­˜åœ¨ï¼Œå°è¯•åˆ›å»º
    try:
        account = Account(
            user_id=user_id,
            currency=currency,
            total_deposit=0,
            total_withdrawal=0,
            realized_profit_loss=0
        )
        db.session.add(account)
        db.session.commit()
        return account
    except Exception as e:
        # å¦‚æœåˆ›å»ºå¤±è´¥ï¼ˆå¯èƒ½æ˜¯å¹¶å‘åˆ›å»ºå¯¼è‡´å”¯ä¸€çº¦æŸå†²çªï¼‰ï¼Œå›æ»šå¹¶é‡æ–°æŸ¥è¯¢
        db.session.rollback()
        account = Account.query.filter_by(user_id=user_id, currency=currency).first()
        if account:
            return account
        # å¦‚æœä»ç„¶ä¸å­˜åœ¨ï¼Œè®°å½•é”™è¯¯å¹¶è¿”å›None
        print(f"âš ï¸ æ— æ³•åˆ›å»ºæˆ–è·å–è´¦æˆ· (user_id={user_id}, currency={currency}): {str(e)}")
        return None

@api_bp.route('/models', methods=['GET'])
def get_models():
    """Get available models for frontend"""
    models = get_models_for_frontend()
    return jsonify(models)

def get_analysis_status(symbol, model_name):
    """Helper to get the latest analyzed date for a symbol and model"""
    latest_signal = StockTradeSignal.query.filter_by(
        symbol=symbol,
        model_name=model_name
    ).order_by(StockTradeSignal.date.desc()).first()
    return latest_signal.date if latest_signal else None

def get_current_position(symbol, model_name):
    """
    Replay history to find if we are currently holding a position for a specific model.
    Returns dict {date, price, reason} or None.
    """
    signals = StockTradeSignal.query.filter_by(
        symbol=symbol,
        model_name=model_name
    ).order_by(StockTradeSignal.date.asc()).all()
    position = None
    for s in signals:
        if s.signal_type == 'BUY':
            # Only open position if we don't have one (simple FIFO/One-at-a-time assumption for now)
            if position is None:
                position = {
                    'date': s.date.strftime('%Y-%m-%d'),
                    'price': s.price,
                    'reason': s.reason
                }
        elif s.signal_type == 'SELL':
            if position:
                position = None # Closed
    return position

def get_user_portfolio_context(user_id, current_symbol, asset_type):
    """
    Get user's complete portfolio information for AI analysis context.
    Returns structured portfolio data including:
    - Total portfolio value
    - List of holdings with their percentages
    - Detailed information for the current symbol (if held)
    """
    from app.services.data_provider import batch_fetcher
    
    if not user_id:
        return None
    
    # Get all user's portfolios
    portfolios = Portfolio.query.filter_by(user_id=user_id).all()
    
    if not portfolios:
        return None
    
    # Calculate total portfolio value
    total_value = 0
    holdings = []
    current_symbol_portfolio = None
    
    for portfolio in portfolios:
        if portfolio.quantity > 0:
            # Get current price
            current_price = batch_fetcher.get_cached_current_price(
                portfolio.symbol, 
                asset_type=portfolio.asset_type,
                currency=portfolio.currency
            )
            
            if current_price:
                position_value = portfolio.quantity * current_price
                total_value += position_value
                
                holding_info = {
                    'symbol': portfolio.symbol,
                    'asset_type': portfolio.asset_type,
                    'quantity': portfolio.quantity,
                    'avg_cost': portfolio.avg_cost,
                    'current_price': current_price,
                    'position_value': position_value,
                    'unrealized_pnl': (current_price - portfolio.avg_cost) * portfolio.quantity,
                    'unrealized_pnl_pct': ((current_price - portfolio.avg_cost) / portfolio.avg_cost * 100) if portfolio.avg_cost > 0 else 0
                }
                
                holdings.append(holding_info)
                
                # Check if this is the current symbol being analyzed
                if portfolio.symbol == current_symbol and portfolio.asset_type == asset_type:
                    current_symbol_portfolio = portfolio
    
    # Calculate percentages
    for holding in holdings:
        holding['percentage'] = (holding['position_value'] / total_value * 100) if total_value > 0 else 0
    
    # Sort by position value (descending)
    holdings.sort(key=lambda x: x['position_value'], reverse=True)
    
    # Build context structure
    context = {
        'total_value': total_value,
        'holdings_count': len(holdings),
        'holdings_summary': [
            {
                'symbol': h['symbol'],
                'asset_type': h['asset_type'],
                'percentage': h['percentage'],
                'unrealized_pnl_pct': h['unrealized_pnl_pct']
            }
            for h in holdings
        ]
    }
    
    # Add detailed info for current symbol if held
    if current_symbol_portfolio:
        # Get transaction history for this symbol
        transactions = Transaction.query.filter_by(
            portfolio_id=current_symbol_portfolio.id,
            user_id=user_id
        ).order_by(Transaction.trade_date.asc()).all()
        
        context['current_symbol_detail'] = {
            'symbol': current_symbol,
            'quantity': current_symbol_portfolio.quantity,
            'avg_cost': current_symbol_portfolio.avg_cost,
            'current_price': next((h['current_price'] for h in holdings if h['symbol'] == current_symbol), None),
            'position_value': next((h['position_value'] for h in holdings if h['symbol'] == current_symbol), None),
            'percentage': next((h['percentage'] for h in holdings if h['symbol'] == current_symbol), 0),
            'unrealized_pnl': next((h['unrealized_pnl'] for h in holdings if h['symbol'] == current_symbol), 0),
            'unrealized_pnl_pct': next((h['unrealized_pnl_pct'] for h in holdings if h['symbol'] == current_symbol), 0),
            'transactions': [
                {
                    'date': t.trade_date.strftime('%Y-%m-%d'),
                    'type': t.transaction_type,
                    'price': t.price,
                    'quantity': t.quantity,
                    'notes': t.notes
                }
                for t in transactions
            ]
        }
    
    return context

@api_bp.route('/recommend', methods=['POST'])
def recommend():
    """
    æ¨èç»“æœå¸¦ç¼“å­˜ï¼ˆä¸€å¤©å†…çš„è¯·æ±‚èµ°ç¼“å­˜ï¼Œæå‡å“åº”é€Ÿåº¦å¹¶é™ä½ API æˆæœ¬ï¼‰
    """
    data = request.json
    model_name = data.get('model', 'gemini-3-flash-preview')
    language = data.get('language', 'zh')
    
    criteria = {
        'market': data.get('market', 'Any'),
        'asset_type': data.get('asset_type', 'STOCK'),
        'include_etf': data.get('include_etf', 'false'),
        'capital': data.get('capital', 'Any'),
        'risk': data.get('risk', 'Any'),
        'frequency': data.get('frequency', 'Any')
    }
    
    # ç”Ÿæˆç­›é€‰æ¡ä»¶çš„å“ˆå¸Œå€¼ï¼ˆç”¨äºåŒºåˆ†ä¸åŒçš„æŸ¥è¯¢ï¼‰
    criteria_str = json.dumps(criteria, sort_keys=True)
    criteria_hash = hashlib.md5(f"{criteria_str}_{model_name}_{language}".encode()).hexdigest()
    
    # è·å–å½“å‰æ—¥æœŸ
    today = datetime.utcnow().date()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å½“å¤©çš„ç¼“å­˜
    cached = RecommendationCache.query.filter_by(
        cache_date=today,
        model_name=model_name,
        language=language,
        criteria_hash=criteria_hash
    ).first()
    
    if cached and cached.recommendation_result:
        print(f"[Recommend] Using cached result for {today}")
        try:
            cached_result = json.loads(cached.recommendation_result)
            cached_result['_cached'] = True  # æ·»åŠ ç¼“å­˜æ ‡è¯†
            return jsonify(cached_result)
        except json.JSONDecodeError as e:
            print(f"JSON decode error for cached recommendation: {e}, regenerating...")
            db.session.delete(cached)
            db.session.commit()
    
    # æ²¡æœ‰ç¼“å­˜ï¼Œè°ƒç”¨ AI ç”Ÿæˆæ¨èï¼ˆAgent æ¨¡å¼ï¼‰
    print(f"[Recommend] No cache found, calling AI for {today}")
    result = ai_analyzer.recommend_stocks_with_agent(criteria, model_name=model_name, language=language)
    
    # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆä½¿ç”¨ upsert æ¨¡å¼ï¼šå¦‚æœå·²å­˜åœ¨åˆ™æ›´æ–°ï¼Œå¦åˆ™æ’å…¥ï¼‰
    try:
        existing_cache = RecommendationCache.query.filter_by(
            cache_date=today,
            model_name=model_name,
            language=language,
            criteria_hash=criteria_hash
        ).first()
        
        if existing_cache:
            # æ›´æ–°ç°æœ‰ç¼“å­˜
            existing_cache.recommendation_result = json.dumps(result)
            existing_cache.created_at = datetime.utcnow()
            db.session.commit()
            print(f"[Recommend] Result updated in cache for {today}")
        else:
            # åˆ›å»ºæ–°ç¼“å­˜
            new_cache = RecommendationCache(
                cache_date=today,
                model_name=model_name,
                language=language,
                criteria_hash=criteria_hash,
                recommendation_result=json.dumps(result)
            )
            db.session.add(new_cache)
            db.session.commit()
            print(f"[Recommend] Result cached for {today}")
    except Exception as e:
        db.session.rollback()
        print(f"Cache save error: {e}")
    
    result['_cached'] = False  # æ·»åŠ ç¼“å­˜æ ‡è¯†
    return jsonify(result)

@api_bp.route('/portfolio_advice', methods=['POST'])
def portfolio_advice():
    data = request.json
    model_name = data.get('model', 'gemini-3-flash-preview')
    language = data.get('language', 'zh')
    
    result = ai_analyzer.analyze_portfolio_item_with_agent(data, model_name=model_name, language=language)
    return jsonify(result)

@api_bp.route('/translate', methods=['POST'])
def translate():
    data = request.json
    text = data.get('text')
    target_lang = data.get('target_lang', 'en')
    model_name = data.get('model', 'gemini-3-flash-preview')
    
    if not text:
        return jsonify({"error": "No text provided"}), 400
        
    result = ai_analyzer.translate_text(text, target_language=target_lang, model_name=model_name)
    return jsonify(result)

@api_bp.route('/search', methods=['GET'])
def search():
    query = request.args.get('q', '')
    search_type = request.args.get('type', 'ALL')
    if not query:
        return jsonify([])
    
    results = DataProvider.search_symbol(query, search_type=search_type)
    return jsonify(results)

@api_bp.route('/current-price', methods=['GET'])
def get_current_price():
    from app.services.data_provider import batch_fetcher
    
    symbol = request.args.get('symbol', '')
    asset_type = request.args.get('asset_type')
    currency = request.args.get('currency')  #  æ–°å¢ï¼šè·å–è´§å¸å‚æ•°
    if not symbol:
        return jsonify({'error': 'Symbol is required'}), 400
    
    # Use cached version to reduce API calls
    price = batch_fetcher.get_cached_current_price(symbol, asset_type=asset_type, currency=currency)
    if price is None:
        return jsonify({'error': 'Could not fetch current price'}), 404
    
    return jsonify({'symbol': symbol, 'price': price})

@api_bp.route('/analyze', methods=['POST'])
def analyze():
    from app.services.data_provider import batch_fetcher
    
    data = request.json
    symbol = data.get('symbol')
    asset_type = data.get('asset_type', 'STOCK')
    is_cn_fund = data.get('is_cn_fund', False)  #  æ–°å¢ï¼šæ˜¯å¦ä¸ºä¸­å›½åŸºé‡‘
    model_name = data.get('model', 'gemini-3-flash-preview') # Default to 2.5 Flash
    language = data.get('language', 'zh')
    
    if not symbol:
        return jsonify({'error': 'Symbol is required'}), 400
        
    # 1. Get K-line Data (Use cached version to reduce API calls)
    kline_data = batch_fetcher.get_cached_kline_data(symbol, period="3y", interval="1d", is_cn_fund=is_cn_fund)
    if not kline_data:
        return jsonify({'error': 'Could not fetch data for symbol'}), 404
    
    # Determine the market data range
    market_dates = [d['date'] for d in kline_data]
    if not market_dates:
        return jsonify({'error': 'Empty market data'}), 404
        
    latest_market_date_str = market_dates[-1]
    latest_market_date = datetime.strptime(latest_market_date_str, '%Y-%m-%d').date()
    
    # --- æ£€æŸ¥ MySQL æ˜¯å¦å·²æœ‰å½“å¤©çš„åˆ†æè®°å½• ---
    existing_log = AnalysisLog.query.filter_by(
        symbol=symbol,
        market_date=latest_market_date,
        model_name=model_name,
        language=language
    ).first()
    
    if existing_log and existing_log.analysis_result:
        print(f"[{symbol}] Using cached analysis from MySQL for {latest_market_date_str}")
        try:
            cached_data = json.loads(existing_log.analysis_result)
            return jsonify(cached_data)
        except json.JSONDecodeError as e:
            print(f"JSON decode error for existing log: {e}, re-analyzing...")
            # å¦‚æœ JSON æŸåï¼Œåˆ é™¤æ—§è®°å½•å¹¶é‡æ–°åˆ†æ
            db.session.delete(existing_log)
            db.session.commit()

    # 2. Check DB for existing signals
    # We want to ensure "Model-specific History" consistency.
    # Each model maintains its own separate trading history.
    
    latest_analyzed_date = get_analysis_status(symbol, model_name)
    
    # Get user information for agent mode
    user = User.query.filter_by(username='default_user').first()
    user_id = user.id if user else None
    
    analysis_result = {
        "analysis_summary": "AI Analysis based on historical data.",
        "trades": [],
        "signals": [],
        "source": "ai_model" # Default assumption
    }
    
    # LOGIC:
    # Case A: No history -> Run Full Initialization (Last 3 Years)
    # Case B: History exists but stale -> Run Incremental (Gap days)
    # Case C: History up to date -> Just read DB
    
    # If using Local Strategy, we skip DB persistence logic for now as per request "Global history... from AI"
    # But user said "System produced history... global". 
    # Let's enforce this logic for AI models. Local strategy is deterministic anyway.
    
    if model_name == "local-strategy":
        analysis_result = ai_analyzer.analyze(
            symbol, 
            kline_data, 
            model_name=model_name, 
            language=language
        )
        return jsonify({
            'symbol': symbol,
            'kline_data': kline_data,
            'analysis': analysis_result,
            'source': 'local'
        })

    # --- AI PERSISTENCE LOGIC ---
    
    new_signals = []
    should_cache = True  # é»˜è®¤å…è®¸ç¼“å­˜ï¼ˆä»DBè¯»å–å†å²æ•°æ®æ—¶ï¼‰
    
    if not latest_analyzed_date:
        print(f"[{symbol}] No history found. Running full initialization...")
        # Agent mode: AI fetches its own data via tool calls
        full_analysis = ai_analyzer.analyze_with_agent(
            symbol, 
            model_name=model_name, 
            language=language,
            asset_type=asset_type,
            user_id=user_id
        )
        
        if full_analysis.get('source') == 'ai_agent':
            # AI åˆ†ææˆåŠŸï¼Œä¿å­˜ä¿¡å·åˆ° DBï¼ˆæŒ‰æ¨¡å‹åˆ†å¼€å­˜å‚¨ï¼‰
            for sig in full_analysis.get('signals', []):
                try:
                    # Check if signal already exists (shouldn't for new init, but safe check)
                    sig_date = datetime.strptime(sig['date'], '%Y-%m-%d').date()
                    exists = StockTradeSignal.query.filter_by(
                        symbol=symbol,
                        date=sig_date,
                        model_name=model_name,
                        asset_type=asset_type
                    ).first()
                    if not exists:
                        new_signal = StockTradeSignal(
                            symbol=symbol,
                            date=sig_date,
                            price=sig['price'],
                            signal_type=sig['type'], # BUY/SELL
                            reason=sig.get('reason', ''),
                            source='ai',
                            model_name=model_name,
                            asset_type=asset_type
                        )
                        db.session.add(new_signal)
                except Exception as e:
                    print(f"Error saving signal: {e}")
            try:
                db.session.commit()
                print(f"[{symbol}] Full history saved.")
            except Exception as e:
                db.session.rollback()
                print(f"DB Commit Error: {e}")
        else:
            # AI å¤±è´¥ï¼Œé™çº§åˆ°æœ¬åœ°ç­–ç•¥ï¼Œä¸ç¼“å­˜æœ¬æ¬¡ç»“æœ
            should_cache = False
            print(f"[{symbol}] AI analysis failed, local strategy used. Will not cache.")
    
    else:
        # Check for gap
        # If latest_market_date > latest_analyzed_date
        # We need to fill the gap.
        # However, generating day-by-day signals for a long gap is slow.
        # For simplicity and robustness, if gap is small (< 5 days), we do incremental?
        # Or just run the standard analysis again but ONLY save the new signals?
        # User requirement: "History data is global... do not change old data".
        # So we must NOT overwrite old signals.
        
        print(f"[{symbol}] Found history up to {latest_analyzed_date}. Market date: {latest_market_date}")
        
        if latest_market_date > latest_analyzed_date:
            print(f"[{symbol}] Incremental update needed.")
            # Agent mode: AI fetches its own data via tool calls
            fresh_analysis = ai_analyzer.analyze_with_agent(
                symbol, 
                model_name=model_name, 
                language=language,
                asset_type=asset_type,
                user_id=user_id
            )
            
            if fresh_analysis.get('source') == 'ai_agent':
                # AI åˆ†ææˆåŠŸï¼Œä¿å­˜æ–°ä¿¡å·åˆ° DBï¼ˆæŒ‰æ¨¡å‹åˆ†å¼€å­˜å‚¨ï¼‰
                for sig in fresh_analysis.get('signals', []):
                    sig_date = datetime.strptime(sig['date'], '%Y-%m-%d').date()
                    if sig_date > latest_analyzed_date:
                        # This is a NEW signal
                        try:
                            new_signal = StockTradeSignal(
                                symbol=symbol,
                                date=sig_date,
                                price=sig['price'],
                                signal_type=sig['type'],
                                reason=sig.get('reason', ''),
                                source='ai',
                                model_name=model_name,
                                asset_type=asset_type
                            )
                            db.session.add(new_signal)
                            print(f"[{symbol}] New signal added for {model_name}: {sig_date} {sig['type']}")
                        except Exception as e:
                            print(f"Error adding signal: {e}")
                try:
                    db.session.commit()
                except Exception as e:
                    db.session.rollback()
            else:
                # AI å¤±è´¥ï¼Œé™çº§åˆ°æœ¬åœ°ç­–ç•¥ï¼Œä¸ç¼“å­˜æœ¬æ¬¡ç»“æœ
                should_cache = False
                print(f"[{symbol}] AI analysis failed during incremental update, local strategy used. Will not cache.")

    # 3. Construct Final Response from DB
    # Now we read the "Model-specific History" from DB to ensure consistency for each model
    
    # Get current user for checking adopted signals
    user = get_user_from_request()
    user_id = user.id if user else None
    
    db_signals = StockTradeSignal.query.filter_by(
        symbol=symbol,
        model_name=model_name,
        asset_type=asset_type
    ).order_by(StockTradeSignal.date.asc()).all()
    
    # Get user's real transactions for this symbol
    user_transactions = []
    if user_id:
        portfolio = Portfolio.query.filter_by(
            user_id=user_id,
            symbol=symbol,
            asset_type=asset_type
        ).first()
        if portfolio:
            user_transactions = Transaction.query.filter_by(
                portfolio_id=portfolio.id,
                user_id=user_id
            ).order_by(Transaction.trade_date.asc()).all()
    
    # Reconstruct 'trades' (pair of Buy/Sell) from signals for the UI
    reconstructed_trades = []
    current_position = None # {date, price, reason}
    
    ui_signals = []
    user_trade_signals = []  # User's real transactions for chart display
    
    # Process AI signals
    for s in db_signals:
        date_str = s.date.strftime('%Y-%m-%d')
        
        # Add to signals list for chart
        ui_signals.append({
            "type": s.signal_type,
            "date": date_str,
            "price": s.price,
            "reason": s.reason,
            "adopted": s.adopted,
            "signal_id": s.id
        })
        
        # Logic to pair trades
        if s.signal_type == 'BUY':
            if current_position is None:
                current_position = {
                    'buy_date': date_str,
                    'buy_price': s.price,
                    'buy_reason': s.reason
                }
        elif s.signal_type == 'SELL':
            if current_position:
                # Close position
                buy_price = current_position['buy_price']
                sell_price = s.price
                ret_pct = ((sell_price - buy_price) / buy_price) * 100
                
                # Calculate days
                d1 = datetime.strptime(current_position['buy_date'], '%Y-%m-%d')
                d2 = s.date
                days = (datetime.combine(d2, datetime.min.time()) - d1).days
                
                reconstructed_trades.append({
                    "buy_date": current_position['buy_date'],
                    "buy_price": round(buy_price, 2),
                    "sell_date": date_str,
                    "sell_price": round(sell_price, 2),
                    "status": "CLOSED",
                    "holding_period": f"{days} days",
                    "return_rate": f"{ret_pct:+.2f}%",
                    "reason": s.reason # Use sell reason
                })
                current_position = None
                
    # Handle open position
    if current_position:
        # Get latest price from kline_data
        latest_close = kline_data[-1]['close']
        latest_date_str = kline_data[-1]['date']
        
        buy_price = current_position['buy_price']
        curr_ret = ((latest_close - buy_price) / buy_price) * 100
        
        d1 = datetime.strptime(current_position['buy_date'], '%Y-%m-%d')
        d2 = datetime.strptime(latest_date_str, '%Y-%m-%d')
        days = (d2 - d1).days
        
        reconstructed_trades.append({
            "buy_date": current_position['buy_date'],
            "buy_price": round(buy_price, 2),
            "sell_date": None,
            "sell_price": None,
            "status": "HOLDING",
            "holding_period": f"{days} days",
            "return_rate": f"{curr_ret:+.2f}% (Open)",
            "reason": current_position['buy_reason']
        })
        
    # Sort desc for UI
    reconstructed_trades.sort(key=lambda x: x['buy_date'], reverse=True)
    
    # Process user's real transactions for chart display
    for trans in user_transactions:
        user_trade_signals.append({
            "type": trans.transaction_type,
            "date": trans.trade_date.strftime('%Y-%m-%d'),
            "price": trans.price,
            "quantity": trans.quantity,
            "notes": trans.notes,
            "source": trans.source,
            "transaction_id": trans.id
        })
    
    # Construct final analysis result
    # We might need a summary. We can fetch the latest summary from AnalysisLog or just use a generic one.
    # Or we can generate a quick summary if needed. 
    # For now, reusing the summary from the fresh analysis (if we ran it) or a placeholder.
    
    summary_text = f"Model-specific History Loaded ({model_name}). "
    if 'fresh_analysis' in locals():
        summary_text = fresh_analysis.get('analysis_summary', summary_text)
    elif 'full_analysis' in locals():
        summary_text = full_analysis.get('analysis_summary', summary_text)
    else:
        # Try to get from latest AnalysisLog as fallback for summary text (filter by model)
        last_log = AnalysisLog.query.filter_by(
            symbol=symbol,
            model_name=model_name
        ).order_by(AnalysisLog.created_at.desc()).first()
        if last_log and last_log.analysis_result:
            try:
                summary_text = json.loads(last_log.analysis_result).get('analysis_summary', summary_text)
            except:
                pass

    final_result = {
        "analysis_summary": summary_text,
        "trades": reconstructed_trades,
        "signals": ui_signals,
        "user_transactions": user_trade_signals,  # User's real transactions
        "source": "ai_model_history"
    }

    final_response = {
        'symbol': symbol,
        'kline_data': kline_data,
        'analysis': final_result,
        'source': 'ai_database'
    }
    
    # --- ä¿å­˜åˆ° MySQL AnalysisLogï¼ˆå½“å¤©çš„åˆ†æç¼“å­˜ï¼‰ ---
    # åªæœ‰å½“æ•°æ®æ¥è‡ª AI åˆ†ææ—¶æ‰ç¼“å­˜ï¼Œæœ¬åœ°ç­–ç•¥é™çº§çš„ç»“æœä¸ç¼“å­˜
    if should_cache:
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆç†è®ºä¸Šä¸åº”è¯¥ï¼Œå› ä¸ºå‰é¢å·²ç»æ£€æŸ¥è¿‡äº†ï¼‰
            existing = AnalysisLog.query.filter_by(
                symbol=symbol,
                market_date=latest_market_date,
                model_name=model_name,
                language=language
            ).first()
            
            if not existing:
                new_log = AnalysisLog(
                    symbol=symbol,
                    market_date=latest_market_date,
                    model_name=model_name,
                    language=language,
                    analysis_result=json.dumps(final_response)
                )
                db.session.add(new_log)
                db.session.commit()
                print(f"[{symbol}] Analysis result saved to MySQL for {latest_market_date_str}")
            else:
                # æ›´æ–°å·²æœ‰è®°å½•
                existing.analysis_result = json.dumps(final_response)
                existing.created_at = datetime.utcnow()
                db.session.commit()
                print(f"[{symbol}] Analysis result updated in MySQL for {latest_market_date_str}")
        except Exception as e:
            db.session.rollback()
            print(f"MySQL Save Error: {e}")
    else:
        print(f"[{symbol}] Skipping cache due to local strategy fallback.")

    return jsonify(final_response)

@api_bp.route('/market_indices', methods=['GET'])
def get_market_indices():
    """Get major market indices for dashboard"""
    from app import r
    import time
    
    # Check cache first (cache for 5 minutes for real-time feel)
    cache_key = 'market_indices'
    try:
        cached = r.get(cache_key)
        if cached:
            return jsonify(json.loads(cached))
    except:
        pass
    
    # Add delay to prevent race condition with trending_stocks endpoint
    time.sleep(2)  # 2 second delay to stagger API calls
    
    # Define major indices with their symbols and metadata
    indices = [
        {'symbol': '^GSPC', 'name': 'S&P 500', 'name_zh': 'æ ‡æ™®500', 'market': 'US', 'icon': 'ğŸ‡ºğŸ‡¸'},
        {'symbol': '^NDX', 'name': 'NASDAQ 100', 'name_zh': 'çº³æ–¯è¾¾å…‹100', 'market': 'US', 'icon': 'ğŸ‡ºğŸ‡¸'},
        {'symbol': '^HSI', 'name': 'Hang Seng Index', 'name_zh': 'æ’ç”ŸæŒ‡æ•°', 'market': 'HK', 'icon': 'ğŸ‡­ğŸ‡°'},
        {'symbol': '3033.HK', 'name': 'Hang Seng Tech', 'name_zh': 'æ’ç”Ÿç§‘æŠ€ETF', 'market': 'HK', 'icon': 'ğŸ‡­ğŸ‡°'},
        {'symbol': '^N225', 'name': 'Nikkei 225', 'name_zh': 'æ—¥ç»225', 'market': 'JP', 'icon': 'ğŸ‡¯ğŸ‡µ'},
        {'symbol': '^KS11', 'name': 'KOSPI', 'name_zh': 'KOSPI', 'market': 'KR', 'icon': 'ğŸ‡°ğŸ‡·'},
        {'symbol': '000001.SS', 'name': 'SSE Index', 'name_zh': 'ä¸Šè¯æŒ‡æ•°', 'market': 'CN', 'icon': 'ğŸ‡¨ğŸ‡³'},
        {'symbol': '399006.SZ', 'name': 'ChiNext', 'name_zh': 'åˆ›ä¸šæ¿æŒ‡', 'market': 'CN', 'icon': 'ğŸ‡¨ğŸ‡³'},
        {'symbol': 'GC=F', 'name': 'Gold', 'name_zh': 'é»„é‡‘', 'market': 'COMMODITY', 'icon': 'ğŸ¥‡'},
        {'symbol': 'CL=F', 'name': 'Crude Oil', 'name_zh': 'åŸæ²¹', 'market': 'COMMODITY', 'icon': 'ğŸ›¢ï¸'},
        {'symbol': 'BTC-USD', 'name': 'Bitcoin', 'name_zh': 'æ¯”ç‰¹å¸', 'market': 'CRYPTO', 'icon': 'â‚¿'}
    ]
    
    result = []
    
    # Extract all symbols for batch fetching
    all_symbols = [idx['symbol'] for idx in indices]
    
    # Batch fetch all historical data in one API call
    from app.services.data_provider import batch_fetcher
    batch_data = batch_fetcher.batch_fetch_history(all_symbols, period='5d', interval='1d')
    
    for index_info in indices:
        try:
            symbol = index_info['symbol']
            used_symbol = symbol
            
            # Get data from batch fetch results
            hist = batch_data.get(symbol, pd.DataFrame())
            
            # Check if data is available
            if hist.empty or len(hist) < 2:
                print(f"Warning: No data for {symbol}, skipping...")
                continue
            
            # Current price and change
            current_price = hist['Close'].iloc[-1]
            prev_close = hist['Close'].iloc[-2]
            change = current_price - prev_close
            change_pct = (change / prev_close) * 100
            
            # Get today's high and low
            today_high = hist['High'].iloc[-1]
            today_low = hist['Low'].iloc[-1]
            
            # Get volume if available
            volume = hist['Volume'].iloc[-1] if 'Volume' in hist.columns else 0
            volume_str = ''
            if volume > 0:
                if volume >= 1e9:
                    volume_str = f"{volume/1e9:.2f}B"
                elif volume >= 1e6:
                    volume_str = f"{volume/1e6:.1f}M"
                else:
                    volume_str = f"{volume/1e3:.1f}K"
            
            # Generate trend data for sparkline (last 5 days)
            trend_points = []
            min_price = hist['Close'].min()
            max_price = hist['Close'].max()
            price_range = max_price - min_price if max_price != min_price else 1
            
            for i, price in enumerate(hist['Close']):
                x = i * 25
                y = 40 - ((price - min_price) / price_range * 35)
                trend_points.append(f"{x},{y:.1f}")
            
            # Format price based on asset type
            if index_info['market'] == 'CRYPTO':
                price_str = f"${current_price:,.2f}"
                decimals = 2
            elif index_info['market'] == 'COMMODITY':
                if 'Gold' in index_info['name']:
                    price_str = f"${current_price:,.2f}"
                else:
                    price_str = f"${current_price:.2f}"
                decimals = 2
            elif index_info['market'] in ['CN', 'HK']:
                price_str = f"{current_price:,.2f}"
                decimals = 2
            else:
                price_str = f"{current_price:,.2f}"
                decimals = 2
            
            result.append({
                'symbol': used_symbol,
                'name': index_info['name'],
                'name_zh': index_info['name_zh'],
                'market': index_info['market'],
                'icon': index_info['icon'],
                'price': price_str,
                'price_raw': float(round(current_price, decimals)),
                'change': float(round(change, decimals)),
                'change_pct': float(round(change_pct, 2)),
                'high': float(round(today_high, decimals)),
                'low': float(round(today_low, decimals)),
                'volume': volume_str,
                'trend_data': ' '.join(trend_points),
                'is_up': 1 if change >= 0 else 0
            })
            
        except Exception as e:
            print(f"Error fetching {index_info['name_zh']} ({index_info['symbol']}): {type(e).__name__}: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # Cache for 5 minutes
    try:
        r.setex(cache_key, 300, json.dumps(result))
    except Exception as e:
        print(f"âš ï¸ Failed to cache market indices: {e}")
    
    return jsonify(result)

@api_bp.route('/trending', methods=['GET'])
def get_trending_stocks():
    """Get trending stocks from various markets by volume"""
    from app import r
    
    # Check cache first (cache for 60 minutes to reduce API calls)
    cache_key = 'trending_stocks'
    try:
        cached = r.get(cache_key)
        if cached:
            return jsonify(json.loads(cached))
    except:
        pass
    
    trending_stocks = []
    
    # US Market: Get top stocks from major indices
    us_symbols = [
        # Tech giants and popular stocks
        'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'TSLA', 'NVDA', 'AMD',
        # Financial and other popular
        'JPM', 'V', 'WMT', 'UNH', 'DIS', 'NFLX', 'BABA', 'PFE'
    ]
    
    # CN Market: Popular A-share stocks
    cn_symbols = [
        '600519.SS', '601318.SS', '600036.SS', '600276.SS',  # è´µå·èŒ…å°ã€ä¸­å›½å¹³å®‰ã€æ‹›å•†é“¶è¡Œã€æ’ç‘åŒ»è¯
        '000858.SZ', '000333.SZ', '002594.SZ', '300750.SZ',  # äº”ç²®æ¶²ã€ç¾çš„é›†å›¢ã€æ¯”äºšè¿ªã€å®å¾·æ—¶ä»£
        '600887.SS', '601012.SS', '600900.SS', '601888.SS'   # ä¼Šåˆ©è‚¡ä»½ã€éš†åŸºç»¿èƒ½ã€é•¿æ±Ÿç”µåŠ›ã€ä¸­å›½ä¸­å…
    ]
    
    # HK Market: Popular HK stocks
    hk_symbols = [
        '0700.HK', '9988.HK', '3690.HK', '2318.HK',  # è…¾è®¯ã€é˜¿é‡Œã€ç¾å›¢ã€å¹³å®‰
        '1810.HK', '0941.HK', '1211.HK', '2382.HK',  # å°ç±³ã€ä¸­å›½ç§»åŠ¨ã€æ¯”äºšè¿ªã€èˆœå®‡å…‰å­¦
        '0175.HK', '1398.HK', '0388.HK', '0005.HK'   # å‰åˆ©æ±½è½¦ã€å·¥å•†é“¶è¡Œã€æ¸¯äº¤æ‰€ã€æ±‡ä¸°æ§è‚¡
    ]
    
    # Combine all symbols for batch fetching
    all_symbols = us_symbols + cn_symbols + hk_symbols
    
    # Market mapping
    symbol_market = {}
    for symbol in us_symbols:
        symbol_market[symbol] = 'US'
    for symbol in cn_symbols:
        symbol_market[symbol] = 'CN'
    for symbol in hk_symbols:
        symbol_market[symbol] = 'HK'
    
    # Batch fetch all historical data in one API call
    from app.services.data_provider import batch_fetcher
    batch_data = batch_fetcher.batch_fetch_history(all_symbols, period='5d', interval='1d')
    
    def process_stock_data(symbol, market, hist):
        """Process stock data from batch fetch results"""
        try:
            if hist.empty or len(hist) < 2:
                return None
            
            # Get current price and change
            current_price = hist['Close'].iloc[-1]
            prev_close = hist['Close'].iloc[-2]
            
            if pd.isna(current_price) or pd.isna(prev_close) or prev_close == 0:
                change_pct = 0.0
            else:
                change_pct = ((current_price - prev_close) / prev_close) * 100
                if pd.isna(change_pct) or math.isinf(change_pct):
                    change_pct = 0.0
            
            # Get volume (use latest day)
            volume = hist['Volume'].iloc[-1] if 'Volume' in hist.columns else 0
            if pd.isna(volume):
                volume = 0
            
            # Skip if volume is too low or zero
            if volume < 100000:
                return None
            
            volume_str = f"{volume/1e6:.1f}M" if volume >= 1e6 else f"{volume/1e3:.1f}K"
            
            # Get stock name from local list (avoiding info API calls)
            from app.services.data_provider import POPULAR_STOCKS
            stock_info = next((s for s in POPULAR_STOCKS if s['symbol'] == symbol), None)
            name = stock_info['name'] if stock_info else symbol
            
            # Format price based on market
            if market == 'US':
                price_str = f"${current_price:.2f}"
                exchange = 'NASDAQ'
            elif market == 'CN':
                price_str = f"Â¥{current_price:.2f}"
                exchange = 'SSE' if '.SS' in symbol else 'SZSE'
            else:  # HK
                price_str = f"HK${current_price:.2f}"
                exchange = 'HKEX'
            
            # Generate mini trend data (last 5 days)
            trend_points = []
            min_price = hist['Close'].min()
            max_price = hist['Close'].max()
            price_range = max_price - min_price if max_price != min_price else 1
            
            for i, price in enumerate(hist['Close']):
                x = 10 + i * 20
                y = 35 - ((price - min_price) / price_range * 25)
                trend_points.append(f"{x},{y:.1f}")
            
            return {
                'symbol': symbol,
                'name': name,
                'price': price_str,
                'change': round(change_pct, 2),
                'volume': volume_str,
                'volume_raw': volume,  # For sorting
                'market': exchange,
                'trendData': ' '.join(trend_points)
            }
            
        except Exception as e:
            print(f"Error processing {symbol}: {e}")
            return None
    
    # Process data from all markets
    for symbol in all_symbols:
        market = symbol_market[symbol]
        hist = batch_data.get(symbol, pd.DataFrame())
        data = process_stock_data(symbol, market, hist)
        if data:
            trending_stocks.append(data)
    
    # Sort by volume (highest first) and take top 12
    trending_stocks.sort(key=lambda x: x['volume_raw'], reverse=True)
    top_stocks = trending_stocks[:12]
    
    # Remove volume_raw from final result
    for stock in top_stocks:
        stock.pop('volume_raw', None)
    
    # Select diverse stocks: aim for 8 total, try to include different markets
    us_stocks = [s for s in top_stocks if s['market'] in ['NASDAQ', 'NYSE']]
    cn_stocks = [s for s in top_stocks if s['market'] in ['SSE', 'SZSE']]
    hk_stocks = [s for s in top_stocks if s['market'] == 'HKEX']
    
    # Pick 3-4 from each market if available
    result = []
    result.extend(us_stocks[:4])
    result.extend(cn_stocks[:2])
    result.extend(hk_stocks[:2])
    
    # If we don't have 8, fill with remaining top volume stocks
    if len(result) < 8:
        for stock in top_stocks:
            if stock not in result and len(result) < 8:
                result.append(stock)
    
    # Ensure we have at least some stocks
    if len(result) == 0:
        print("Warning: No stocks fetched, using fallback")
        result = [
            {'symbol': 'AAPL', 'name': 'Apple', 'price': '$195', 'change': 1.5, 'volume': '45M', 'market': 'NASDAQ', 'trendData': '10,28 30,25 50,30 70,27 90,32'},
            {'symbol': 'TSLA', 'name': 'Tesla', 'price': '$245', 'change': -1.2, 'volume': '95M', 'market': 'NASDAQ', 'trendData': '10,15 30,18 50,22 70,25 90,20'}
        ]
    
    print(f"Returning {len(result)} trending stocks")
    
    # Cache for 60 minutes
    try:
        r.setex(cache_key, 3600, json.dumps(result))
    except:
        pass
    
    return jsonify(result)

@api_bp.route('/market_news', methods=['GET'])
def get_market_news():
    """Get latest market news and insights"""
    import yfinance as yf
    from app import r
    
    # Check cache first (cache for 15 minutes)
    cache_key = 'market_news'
    try:
        cached = r.get(cache_key)
        if cached:
            print(f"Using cached market news")
            return jsonify(json.loads(cached))
    except:
        print(f"Error checking market news cache")
        pass
    
    news_items = []
    
    # Get news from different sources using yfinance
    try:
        # Fetch news for major indices to represent global market news
        # S&P 500, Nasdaq, Dow Jones, Gold, Oil
        tickers = ["^GSPC", "^IXIC", "^DJI", "GC=F", "CL=F"]
        
        for symbol in tickers:
            try:
                ticker = yf.Ticker(symbol)
                news = ticker.news
                
                for item in news:
                    try:
                        # Parse timestamp
                        published_time = datetime.fromtimestamp(item.get('providerPublishTime', 0))
                        time_ago = get_time_ago(published_time)
                        
                        title = item.get('title', '')
                        
                        # Determine news type based on title keywords
                        news_type = 'news'
                        icon = 'ğŸ“°'
                        
                        title_lower = title.lower()
                        if any(word in title_lower for word in ['earnings', 'revenue', 'profit', 'report']):
                            news_type = 'earnings'
                            icon = 'ğŸ“Š'
                        elif any(word in title_lower for word in ['surge', 'plunge', 'jump', 'drop', 'rally', 'crash']):
                            news_type = 'market'
                            icon = 'ğŸ“ˆ'
                        elif any(word in title_lower for word in ['fed', 'rate', 'policy', 'central bank']):
                            news_type = 'policy'
                            icon = 'ğŸ›ï¸'
                        
                        news_items.append({
                            'title': title,
                            'source': item.get('publisher', 'Unknown'),
                            'time_ago': time_ago,
                            'published': published_time.isoformat(),
                            'url': item.get('link', '#'),
                            'type': news_type,
                            'icon': icon,
                            'id': item.get('uuid')
                        })
                    except Exception as e:
                        print(f"Error processing news item: {e}")
                        continue
            except Exception as e:
                print(f"Error fetching news for {symbol}: {e}")
                continue

    except Exception as e:
        print(f"Error fetching market news: {e}")

    # Remove duplicates by URL or ID
    seen_ids = set()
    unique_news = []
    for item in news_items:
        # Use ID or URL as identifier
        identifier = item.get('id') or item.get('url', '')
        if identifier and identifier not in seen_ids:
            seen_ids.add(identifier)
            unique_news.append(item)
    
    # Sort by publish time (newest first) and limit to 10
    unique_news.sort(key=lambda x: x['published'], reverse=True)
    result = unique_news[:10]
    
    # Cache for 15 minutes
    try:
        r.setex(cache_key, 900, json.dumps(result))
    except:
        pass
    
    return jsonify(result)
def get_time_ago(dt):
    """Calculate time ago string"""
    now = datetime.utcnow()
    diff = now - dt.replace(tzinfo=None)
    
    seconds = diff.total_seconds()
    
    if seconds < 60:
        return 'Just now'
    elif seconds < 3600:
        minutes = int(seconds / 60)
        return f'{minutes}m ago'
    elif seconds < 86400:
        hours = int(seconds / 3600)
        return f'{hours}h ago'
    else:
        days = int(seconds / 86400)
        return f'{days}d ago'

# ========== ç”¨æˆ·è®¤è¯ç›¸å…³ API ==========

@api_bp.route('/auth/register', methods=['POST'])
def register():
    """ç”¨æˆ·æ³¨å†Œ"""
    data = request.json
    nickname = data.get('nickname', '').strip()
    email = data.get('email', '').strip()
    password = data.get('password', '').strip()
    email_confirmed = data.get('email_confirmed', False)  # ç”¨æˆ·æ˜¯å¦å·²ç¡®è®¤é‚®ç®±
    
    # éªŒè¯è¾“å…¥
    if not nickname or len(nickname) < 1:
        return jsonify({'error': 'æ˜µç§°ä¸èƒ½ä¸ºç©º'}), 400
    
    if not email:
        return jsonify({'error': 'é‚®ç®±ä¸èƒ½ä¸ºç©º'}), 400
    
    if not password or len(password) < 6:
        return jsonify({'error': 'å¯†ç é•¿åº¦è‡³å°‘ä¸º6ä½'}), 400
    
    # é‚®ç®±éªŒè¯ï¼ˆä½¿ç”¨ Rapid Email Verifier APIï¼‰
    validation_result = email_validator.validate_email(email)
    if not validation_result['valid']:
        return jsonify({'error': validation_result['reason']}), 400
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦äºŒæ¬¡ç¡®è®¤ï¼ˆPROBABLY_VALID çŠ¶æ€ï¼‰
    details = validation_result.get('details', {})
    status = details.get('status', '')
    typo_suggestion = details.get('typoSuggestion', '')
    score = details.get('score', 100)
    
    # å¦‚æœæ˜¯ PROBABLY_VALID çŠ¶æ€ä¸”ç”¨æˆ·æœªç¡®è®¤ï¼Œè¦æ±‚ç”¨æˆ·ç¡®è®¤
    if status == 'PROBABLY_VALID' and not email_confirmed:
        return jsonify({
            'success': False,
            'need_confirmation': True,
            'email': email,
            'typo_suggestion': typo_suggestion,
            'score': score,
            'message': 'æ£€æµ‹åˆ°é‚®ç®±å¯èƒ½å­˜åœ¨æ‹¼å†™é”™è¯¯ï¼Œè¯·ç¡®è®¤æ˜¯å¦ç»§ç»­ä½¿ç”¨æ­¤é‚®ç®±'
        }), 200
    
    # æ£€æŸ¥é‚®ç®±æ˜¯å¦å·²å­˜åœ¨
    existing_user = User.query.filter_by(email=email).first()
    if existing_user:
        return jsonify({'error': 'è¯¥é‚®ç®±å·²è¢«æ³¨å†Œ'}), 400
    
    # åˆ›å»ºæ–°ç”¨æˆ·
    user = User(
        nickname=nickname,
        email=email
    )
    user.set_password(password)
    user.generate_session_id()
    
    db.session.add(user)
    db.session.commit()
    
    return jsonify({
        'success': True,
        'user': user.to_dict(),
        'message': 'æ³¨å†ŒæˆåŠŸ'
    })

@api_bp.route('/auth/login', methods=['POST'])
def login():
    """ç”¨æˆ·ç™»å½•"""
    data = request.json
    email = data.get('email', '').strip()
    password = data.get('password', '').strip()
    session_id = data.get('session_id')  # ç”¨äºè‡ªåŠ¨ç™»å½•
    
    # è‡ªåŠ¨ç™»å½•ï¼šå¦‚æœæœ‰session_idï¼Œå°è¯•æŸ¥æ‰¾ç”¨æˆ·
    if session_id:
        user = User.query.filter_by(session_id=session_id).first()
        if user:
            user.last_login = datetime.utcnow()
            db.session.commit()
            return jsonify({
                'success': True,
                'user': user.to_dict(),
                'message': 'è‡ªåŠ¨ç™»å½•æˆåŠŸ'
            })
    
    # éªŒè¯è¾“å…¥
    if not email:
        return jsonify({'error': 'é‚®ç®±ä¸èƒ½ä¸ºç©º'}), 400
    
    if not password:
        return jsonify({'error': 'å¯†ç ä¸èƒ½ä¸ºç©º'}), 400
    
    # æŸ¥æ‰¾ç”¨æˆ·
    user = User.query.filter_by(email=email).first()
    if not user:
        return jsonify({'error': 'é‚®ç®±æˆ–å¯†ç é”™è¯¯'}), 401
    
    # éªŒè¯å¯†ç 
    if not user.check_password(password):
        return jsonify({'error': 'é‚®ç®±æˆ–å¯†ç é”™è¯¯'}), 401
    
    # ç”Ÿæˆæ–°çš„ä¼šè¯ID
    user.generate_session_id()
    user.last_login = datetime.utcnow()
    db.session.commit()
    
    return jsonify({
        'success': True,
        'user': user.to_dict(),
        'message': 'ç™»å½•æˆåŠŸ'
    })

@api_bp.route('/auth/logout', methods=['POST'])
def logout():
    """ç”¨æˆ·æ³¨é”€"""
    data = request.json
    session_id = data.get('session_id')
    
    if not session_id:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    user = User.query.filter_by(session_id=session_id).first()
    if user:
        # æ¸…é™¤ä¼šè¯ID
        user.session_id = None
        db.session.commit()
    
    return jsonify({
        'success': True,
        'message': 'æ³¨é”€æˆåŠŸ'
    })

@api_bp.route('/auth/check', methods=['GET'])
def check_auth():
    """æ£€æŸ¥ç”¨æˆ·ç™»å½•çŠ¶æ€"""
    session_id = request.args.get('session_id')
    if not session_id:
        return jsonify({'authenticated': False}), 401
    
    user = User.query.filter_by(session_id=session_id).first()
    if user:
        return jsonify({
            'authenticated': True,
            'user': user.to_dict()
        })
    
    return jsonify({'authenticated': False}), 401

# ========== ä»»åŠ¡ç®¡ç†ç›¸å…³ API ==========

def get_user_from_request():
    """ä»è¯·æ±‚ä¸­è·å–ç”¨æˆ·"""
    session_id = request.headers.get('X-Session-ID')
    if not session_id and request.is_json and request.json:
        session_id = request.json.get('session_id')
    if not session_id:
        return None
    return User.query.filter_by(session_id=session_id).first()

@api_bp.route('/tasks/create', methods=['POST'])
def create_task():
    """åˆ›å»ºå¼‚æ­¥ä»»åŠ¡"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    data = request.json
    task_type = data.get('task_type')  # 'kline_analysis', 'portfolio_diagnosis', 'stock_recommendation'
    task_params = data.get('task_params', {})
    
    if not task_type:
        return jsonify({'error': 'ä»»åŠ¡ç±»å‹ä¸èƒ½ä¸ºç©º'}), 400
    
    # åˆ›å»ºä»»åŠ¡
    task_id = task_service.create_task(user.id, task_type, task_params)
    
    return jsonify({
        'success': True,
        'task_id': task_id
    })

@api_bp.route('/tasks/<task_id>', methods=['GET'])
def get_task(task_id):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    task = task_service.get_task(task_id, user.id)
    if not task:
        return jsonify({'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404
    
    return jsonify(task)

@api_bp.route('/tasks', methods=['GET'])
def list_tasks():
    """è·å–ç”¨æˆ·çš„ä»»åŠ¡åˆ—è¡¨"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    status = request.args.get('status')  # å¯é€‰ç­›é€‰ï¼šrunning, completed, terminated, failed
    tasks = task_service.get_user_tasks(user.id, status=status)
    
    return jsonify({
        'tasks': tasks,
        'total': len(tasks)
    })

@api_bp.route('/tasks/<task_id>/terminate', methods=['POST'])
def terminate_task(task_id):
    """ç»ˆæ­¢ä»»åŠ¡"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    success = task_service.terminate_task(task_id, user.id)
    if not success:
        return jsonify({'error': 'æ— æ³•ç»ˆæ­¢ä»»åŠ¡ï¼ˆä»»åŠ¡ä¸å­˜åœ¨æˆ–å·²å®Œæˆï¼‰'}), 400
    
    return jsonify({'success': True})

# ========== ä¿®æ”¹åŸæœ‰çš„åˆ†æAPIï¼Œæ”¹ä¸ºåˆ›å»ºä»»åŠ¡ ==========

@api_bp.route('/analyze_async', methods=['POST'])
def analyze_async():
    """å¼‚æ­¥åˆ†æè‚¡ç¥¨ï¼ˆåˆ›å»ºä»»åŠ¡ï¼‰"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    data = request.json
    symbol = data.get('symbol')
    asset_type = data.get('asset_type', 'STOCK')
    is_cn_fund = data.get('is_cn_fund', False)  #  æ–°å¢ï¼šæ˜¯å¦ä¸ºä¸­å›½åŸºé‡‘
    model_name = data.get('model', 'gemini-3-flash-preview')
    language = data.get('language', 'zh')
    
    if not symbol:
        return jsonify({'error': 'è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º'}), 400
    
    # å¹‚ç­‰æ€§æ£€æŸ¥ï¼šæ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„ç›¸åŒä»»åŠ¡
    existing_task = Task.query.filter_by(
        user_id=user.id,
        task_type='kline_analysis',
        status='running'
    ).order_by(Task.created_at.desc()).first()
    
    if existing_task:
        try:
            task_params = json.loads(existing_task.task_params) if existing_task.task_params else {}
            existing_symbol = task_params.get('symbol')
            existing_model = task_params.get('model', 'gemini-3-flash-preview')
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç›¸åŒçš„è‚¡ç¥¨å’Œæ¨¡å‹
            if existing_symbol == symbol and existing_model == model_name:
                return jsonify({
                    'success': False,
                    'error': 'duplicate_task',
                    'message': f'å·²æœ‰æ­£åœ¨è¿è¡Œçš„ {symbol} åˆ†æä»»åŠ¡',
                    'existing_task_id': existing_task.task_id,
                    'existing_task_created_at': existing_task.created_at.isoformat()
                }), 409  # 409 Conflict
        except (json.JSONDecodeError, AttributeError):
            # å¦‚æœè§£æå¤±è´¥ï¼Œç»§ç»­åˆ›å»ºæ–°ä»»åŠ¡
            pass
    
    # åˆ›å»ºä»»åŠ¡
    task_id = task_service.create_task(user.id, 'kline_analysis', {
        'symbol': symbol,
        'asset_type': asset_type,
        'is_cn_fund': is_cn_fund,  #  æ–°å¢ï¼šä¼ é€’ä¸­å›½åŸºé‡‘æ ‡å¿—
        'model': model_name,
        'language': language
    })
    
    return jsonify({
        'success': True,
        'task_id': task_id
    })

@api_bp.route('/portfolio_advice_async', methods=['POST'])
def portfolio_advice_async():
    """å¼‚æ­¥æŒä»“è¯Šæ–­ï¼ˆåˆ›å»ºä»»åŠ¡ï¼‰"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    data = request.json
    model_name = data.get('model', 'gemini-3-flash-preview')
    language = data.get('language', 'zh')
    
    # åˆ›å»ºä»»åŠ¡
    task_id = task_service.create_task(user.id, 'portfolio_diagnosis', {
        **data,
        'model': model_name,
        'language': language
    })
    
    return jsonify({
        'success': True,
        'task_id': task_id
    })

@api_bp.route('/recommend_async', methods=['POST'])
def recommend_async():
    """å¼‚æ­¥è‚¡ç¥¨æ¨èï¼ˆåˆ›å»ºä»»åŠ¡ï¼‰"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    data = request.json
    model_name = data.get('model', 'gemini-3-flash-preview')
    language = data.get('language', 'zh')
    
    criteria = {
        'market': data.get('market', 'Any'),
        'asset_type': data.get('asset_type', 'STOCK'),
        'include_etf': data.get('include_etf', 'false'),
        'capital': data.get('capital', 'Any'),
        'risk': data.get('risk', 'Any'),
        'frequency': data.get('frequency', 'Any')
    }
    
    # åˆ›å»ºä»»åŠ¡
    task_id = task_service.create_task(user.id, 'stock_recommendation', {
        **criteria,
        'model': model_name,
        'language': language
    })
    
    return jsonify({
        'success': True,
        'task_id': task_id
    })

# ========== è™šæ‹ŸæŒä»“ç®¡ç† API ==========

@api_bp.route('/portfolios', methods=['GET'])
def get_portfolios():
    """è·å–ç”¨æˆ·çš„æ‰€æœ‰æŒä»“ï¼ˆå¿«é€Ÿè¿”å›åŸºç¡€æ•°æ®ï¼Œä¸å«å®æ—¶ä»·æ ¼å’Œåç§°ï¼‰"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    # è·å–æ‰€æœ‰æŒä»“ï¼Œä½†è¿‡æ»¤æ‰æ•°é‡ä¸º0çš„éç°é‡‘æŒä»“
    all_portfolios = Portfolio.query.filter_by(user_id=user.id).all()
    portfolios = [p for p in all_portfolios if p.total_quantity > 0 or p.asset_type == 'CASH']
    
    # å¼•å…¥ batch_fetcher
    from app.services.data_provider import batch_fetcher
    
    # åªè¿”å›åŸºç¡€æ•°æ®ï¼Œä¸è·å–å®æ—¶ä»·æ ¼å’Œåç§°
    portfolios_data = []
    for p in portfolios:
        portfolio_dict = p.to_dict()
        
        # ä½¿ç”¨ symbol ä½œä¸ºé»˜è®¤åç§°
        portfolio_dict['name'] = p.symbol
        
        # è·å–æ±‡ç‡
        exchange_rate = 1.0
        currency = p.currency.upper() if p.currency else 'USD'
        
        if currency != 'USD':
            try:
                exchange_rate = batch_fetcher.get_cached_exchange_rate(currency, 'USD')
            except Exception as e:
                print(f"Failed to get exchange rate for {currency}: {e}")
        
        portfolio_dict['exchange_rate'] = exchange_rate
        portfolio_dict['currency'] = currency
        
        # ä½¿ç”¨æˆæœ¬ä»·ä½œä¸ºå½“å‰ä»·æ ¼ï¼ˆå¿«é€Ÿè¿”å›ï¼‰
        if p.asset_type == 'CASH':
            portfolio_dict['current_price'] = 1.0
            portfolio_dict['current_value'] = p.total_quantity
            portfolio_dict['profit_loss'] = 0.0
            portfolio_dict['profit_loss_percent'] = 0.0
            portfolio_dict['value_in_usd'] = p.total_quantity * exchange_rate
        else:
            portfolio_dict['current_price'] = p.avg_cost
            portfolio_dict['current_value'] = p.total_cost
            portfolio_dict['profit_loss'] = 0.0
            portfolio_dict['profit_loss_percent'] = 0.0
            portfolio_dict['value_in_usd'] = p.total_cost * exchange_rate
        
        portfolios_data.append(portfolio_dict)
    
    # è·å– USD åˆ° CNY çš„æ±‡ç‡
    usd_to_cny = 1.0
    try:
        usd_to_cny = batch_fetcher.get_cached_exchange_rate('USD', 'CNY')
    except Exception as e:
        print(f"Failed to get USD to CNY rate: {e}")

    return jsonify({
        'portfolios': portfolios_data,
        'rates': {
            'USD_CNY': usd_to_cny
        }
    })

@api_bp.route('/portfolios/refresh', methods=['GET'])
def refresh_portfolios():
    """å¼‚æ­¥åˆ·æ–°æŒä»“æ•°æ®ï¼ˆè·å–æœ€æ–°ä»·æ ¼å’Œæ ‡çš„åç§°ï¼‰"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    # è·å–æ‰€æœ‰æŒä»“ï¼Œä½†è¿‡æ»¤æ‰æ•°é‡ä¸º0çš„éç°é‡‘æŒä»“
    all_portfolios = Portfolio.query.filter_by(user_id=user.id).all()
    portfolios = [p for p in all_portfolios if p.total_quantity > 0 or p.asset_type == 'CASH']
    
    # å¼•å…¥ batch_fetcher
    from app.services.data_provider import batch_fetcher
    
    # ä¸ºæ¯ä¸ªæŒä»“æ·»åŠ å®æ—¶ä»·æ ¼å’Œç›ˆäºä¿¡æ¯
    portfolios_with_price = []
    for p in portfolios:
        portfolio_dict = p.to_dict()
        
        #  è·å–æ ‡çš„å…¨å
        try:
            name = DataProvider.get_symbol_name(
                p.symbol, 
                asset_type=p.asset_type,
                currency=p.currency
            )
            portfolio_dict['name'] = name if name else p.symbol
        except Exception as e:
            print(f"Failed to get name for {p.symbol}: {e}")
            portfolio_dict['name'] = p.symbol
        
        # è·å–æ±‡ç‡
        exchange_rate = 1.0
        currency = p.currency.upper() if p.currency else 'USD'
        
        if currency != 'USD':
            try:
                exchange_rate = batch_fetcher.get_cached_exchange_rate(currency, 'USD')
            except Exception as e:
                print(f"Failed to get exchange rate for {currency}: {e}")
        
        portfolio_dict['exchange_rate'] = exchange_rate
        portfolio_dict['currency'] = currency
        
        # ç°é‡‘èµ„äº§ä¸éœ€è¦è·å–å®æ—¶ä»·æ ¼
        if p.asset_type == 'CASH':
            portfolio_dict['current_price'] = 1.0
            portfolio_dict['current_value'] = p.total_quantity
            portfolio_dict['profit_loss'] = 0.0
            portfolio_dict['profit_loss_percent'] = 0.0
            portfolio_dict['value_in_usd'] = p.total_quantity * exchange_rate
            portfolio_dict['daily_change_percent'] = 0.0
        else:
            # è·å–å®æ—¶ä»·æ ¼
            try:
                current_price = batch_fetcher.get_cached_current_price(
                    p.symbol, 
                    asset_type=p.asset_type,
                    currency=currency
                )
                
                if current_price:
                    portfolio_dict['current_price'] = float(current_price)
                    current_value = current_price * p.total_quantity
                    portfolio_dict['current_value'] = current_value
                    portfolio_dict['profit_loss'] = current_value - p.total_cost
                    portfolio_dict['profit_loss_percent'] = ((current_value - p.total_cost) / p.total_cost * 100) if p.total_cost > 0 else 0
                    portfolio_dict['value_in_usd'] = current_value * exchange_rate
                else:
                    portfolio_dict['current_price'] = p.avg_cost
                    portfolio_dict['current_value'] = p.total_cost
                    portfolio_dict['profit_loss'] = 0.0
                    portfolio_dict['profit_loss_percent'] = 0.0
                    portfolio_dict['value_in_usd'] = p.total_cost * exchange_rate
                
                # è·å–ä»Šæ—¥æ¶¨è·Œå¹…
                try:
                    daily_change = batch_fetcher.get_cached_daily_change(
                        p.symbol,
                        asset_type=p.asset_type,
                        currency=currency
                    )
                    portfolio_dict['daily_change_percent'] = daily_change if daily_change is not None else 0.0
                except Exception as e:
                    print(f"Failed to get daily change for {p.symbol}: {e}")
                    portfolio_dict['daily_change_percent'] = 0.0
                    
            except Exception as e:
                print(f"Failed to get price for {p.symbol}: {e}")
                portfolio_dict['current_price'] = p.avg_cost
                portfolio_dict['current_value'] = p.total_cost
                portfolio_dict['profit_loss'] = 0.0
                portfolio_dict['profit_loss_percent'] = 0.0
                portfolio_dict['value_in_usd'] = p.total_cost * exchange_rate
                portfolio_dict['daily_change_percent'] = 0.0
        
        portfolios_with_price.append(portfolio_dict)
    
    # è·å– USD åˆ° CNY çš„æ±‡ç‡
    usd_to_cny = 1.0
    try:
        usd_to_cny = batch_fetcher.get_cached_exchange_rate('USD', 'CNY')
    except Exception as e:
        print(f"Failed to get USD to CNY rate: {e}")

    return jsonify({
        'portfolios': portfolios_with_price,
        'rates': {
            'USD_CNY': usd_to_cny
        }
    })

@api_bp.route('/portfolios/<int:portfolio_id>', methods=['GET'])
def get_portfolio(portfolio_id):
    """è·å–å•ä¸ªæŒä»“è¯¦æƒ…ï¼ˆåŒ…å«äº¤æ˜“è®°å½•ï¼‰"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    portfolio = Portfolio.query.filter_by(id=portfolio_id, user_id=user.id).first()
    if not portfolio:
        return jsonify({'error': 'æŒä»“ä¸å­˜åœ¨'}), 404
    
    portfolio_dict = portfolio.to_dict()
    portfolio_dict['transactions'] = [t.to_dict() for t in portfolio.transactions]
    
    return jsonify(portfolio_dict)

@api_bp.route('/portfolios', methods=['POST'])
def create_portfolio():
    """åˆ›å»ºæ–°æŒä»“ï¼ˆé¦–æ¬¡ä¹°å…¥ï¼‰"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    data = request.json
    symbol = data.get('symbol')
    asset_type = data.get('asset_type', 'STOCK')
    currency = data.get('currency', 'USD')
    
    if not symbol:
        return jsonify({'error': 'æ ‡çš„ä»£ç ä¸èƒ½ä¸ºç©º'}), 400
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    existing = Portfolio.query.filter_by(
        user_id=user.id,
        symbol=symbol,
        asset_type=asset_type,
        currency=currency
    ).first()
    
    if existing:
        return jsonify({'error': 'è¯¥æŒä»“å·²å­˜åœ¨'}), 400
    
    # åˆ›å»ºæŒä»“
    portfolio = Portfolio(
        user_id=user.id,
        symbol=symbol,
        asset_type=asset_type,
        currency=currency,
        total_quantity=0,
        avg_cost=0,
        total_cost=0
    )
    
    db.session.add(portfolio)
    db.session.commit()
    
    return jsonify({
        'success': True,
        'portfolio': portfolio.to_dict()
    })

@api_bp.route('/portfolios/<int:portfolio_id>', methods=['PUT'])
def update_portfolio(portfolio_id):
    """æ›´æ–°æŒä»“ä¿¡æ¯ï¼ˆä¸»è¦ç”¨äºç¼–è¾‘ç°é‡‘ä½™é¢ï¼‰"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    portfolio = Portfolio.query.filter_by(id=portfolio_id, user_id=user.id).first()
    if not portfolio:
        return jsonify({'error': 'æŒä»“ä¸å­˜åœ¨'}), 404
    
    data = request.json
    
    # åªå…è®¸æ›´æ–°ç°é‡‘è´¦æˆ·çš„ä½™é¢
    if portfolio.asset_type == 'CASH':
        if 'total_quantity' in data:
            try:
                new_balance = float(data['total_quantity'])
                if new_balance < 0:
                    return jsonify({'error': 'ä½™é¢ä¸èƒ½ä¸ºè´Ÿæ•°'}), 400
                portfolio.total_quantity = new_balance
                portfolio.total_cost = new_balance  # ç°é‡‘çš„æˆæœ¬ç­‰äºä½™é¢
                db.session.commit()
                return jsonify({
                    'success': True,
                    'portfolio': portfolio.to_dict()
                })
            except ValueError:
                return jsonify({'error': 'ä½™é¢æ ¼å¼é”™è¯¯'}), 400
    else:
        return jsonify({'error': 'åªèƒ½ç¼–è¾‘ç°é‡‘è´¦æˆ·ä½™é¢'}), 403

@api_bp.route('/portfolios/<int:portfolio_id>', methods=['DELETE'])
def delete_portfolio(portfolio_id):
    """åˆ é™¤æŒä»“ï¼ˆä¼šçº§è”åˆ é™¤æ‰€æœ‰äº¤æ˜“è®°å½•ï¼‰"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    portfolio = Portfolio.query.filter_by(id=portfolio_id, user_id=user.id).first()
    if not portfolio:
        return jsonify({'error': 'æŒä»“ä¸å­˜åœ¨'}), 404
    
    db.session.delete(portfolio)
    db.session.commit()
    
    return jsonify({'success': True})

# ========== äº¤æ˜“è®°å½•ç®¡ç† API ==========

@api_bp.route('/transactions', methods=['POST'])
def create_transaction():
    """æ·»åŠ äº¤æ˜“è®°å½•"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    data = request.json
    symbol = data.get('symbol')
    asset_type = data.get('asset_type', 'STOCK')
    transaction_type = data.get('transaction_type')  # BUY or SELL
    trade_date_str = data.get('trade_date')
    price = data.get('price')
    quantity = data.get('quantity')
    total_amount = data.get('total_amount')
    notes = data.get('notes', '')
    source = data.get('source', 'manual')
    currency = data.get('currency', 'USD')
    
    # éªŒè¯å¿…å¡«å­—æ®µ
    if not all([symbol, transaction_type, trade_date_str, price]):
        return jsonify({'error': 'ç¼ºå°‘å¿…å¡«å­—æ®µ'}), 400
        
    if quantity is None and total_amount is None:
        return jsonify({'error': 'å¿…é¡»æä¾›æ•°é‡æˆ–æ€»é‡‘é¢'}), 400
    
    if transaction_type not in ['BUY', 'SELL']:
        return jsonify({'error': 'äº¤æ˜“ç±»å‹å¿…é¡»æ˜¯ BUY æˆ– SELL'}), 400
    
    try:
        price = float(price)
        if quantity is not None:
            quantity = float(quantity)
        elif total_amount is not None:
            total_amount = float(total_amount)
            if price <= 0:
                return jsonify({'error': 'ä»·æ ¼å¿…é¡»å¤§äº0'}), 400
            quantity = total_amount / price
            
        trade_date = datetime.strptime(trade_date_str, '%Y-%m-%d').date()
    except ValueError as e:
        return jsonify({'error': f'æ•°æ®æ ¼å¼é”™è¯¯: {str(e)}'}), 400
    
    # æŸ¥æ‰¾æˆ–åˆ›å»ºæŒä»“
    portfolio = Portfolio.query.filter_by(
        user_id=user.id,
        symbol=symbol,
        asset_type=asset_type,
        currency=currency
    ).first()
    
    if not portfolio:
        # å¦‚æœæ˜¯å–å‡ºæ“ä½œä½†æ²¡æœ‰æŒä»“ï¼ŒæŠ¥é”™
        if transaction_type == 'SELL':
            return jsonify({'error': 'æ²¡æœ‰è¯¥æ ‡çš„çš„æŒä»“ï¼Œæ— æ³•å–å‡º'}), 400
        
        # åˆ›å»ºæ–°æŒä»“
        portfolio = Portfolio(
            user_id=user.id,
            symbol=symbol,
            asset_type=asset_type,
            currency=currency,
            total_quantity=0,
            avg_cost=0,
            total_cost=0
        )
        db.session.add(portfolio)
        db.session.flush()
    
    # è®¡ç®—äº¤æ˜“é‡‘é¢
    amount = price * quantity
    
    # æ›´æ–°æŒä»“
    if transaction_type == 'BUY':
        # ä¹°å…¥ï¼šæ‰£é™¤ç°é‡‘
        if asset_type != 'CASH':  # éç°é‡‘èµ„äº§æ‰éœ€è¦æ‰£é™¤ç°é‡‘
            success, message = update_cash_balance(
                user_id=user.id,
                currency=currency,
                amount=amount,
                transaction_type='SELL',  # æ‰£é™¤ç°é‡‘ç”¨SELL
                trade_date=trade_date,
                notes=f'ä¹°å…¥ {symbol} {quantity} @ {price}'
            )
            if not success:
                db.session.rollback()
                return jsonify({'error': message}), 400
        
        new_total_cost = portfolio.total_cost + amount
        new_total_quantity = portfolio.total_quantity + quantity
        portfolio.avg_cost = new_total_cost / new_total_quantity if new_total_quantity > 0 else 0
        portfolio.total_cost = new_total_cost
        portfolio.total_quantity = new_total_quantity
    else:  # SELL
        if portfolio.total_quantity < quantity:
            return jsonify({'error': f'æŒä»“æ•°é‡ä¸è¶³ï¼Œå½“å‰æŒä»“: {portfolio.total_quantity}'}), 400
        
        # æŒ‰å¹³å‡æˆæœ¬è®¡ç®—å–å‡ºæˆæœ¬
        sell_cost = portfolio.avg_cost * quantity
        
        # è®¡ç®—å·²å®ç°æ”¶ç›Š
        realized_pnl = amount - sell_cost
        
        # å–å‡ºï¼šå¢åŠ ç°é‡‘
        if asset_type != 'CASH':  # éç°é‡‘èµ„äº§æ‰éœ€è¦å¢åŠ ç°é‡‘
            success, message = update_cash_balance(
                user_id=user.id,
                currency=currency,
                amount=amount,
                transaction_type='BUY',  # å¢åŠ ç°é‡‘ç”¨BUY
                trade_date=trade_date,
                notes=f'å–å‡º {symbol} {quantity} @ {price}'
            )
            if not success:
                db.session.rollback()
                return jsonify({'error': message}), 400
            
            # æ›´æ–°è´¦æˆ·çš„å·²å®ç°æ”¶ç›Š
            account = Account.query.filter_by(user_id=user.id, currency=currency).first()
            if account:
                account.realized_profit_loss += realized_pnl
        
        portfolio.total_cost -= sell_cost
        portfolio.total_quantity -= quantity
        
        # å¦‚æœå…¨éƒ¨å–å‡ºï¼Œé‡ç½®å¹³å‡æˆæœ¬
        if portfolio.total_quantity == 0:
            portfolio.avg_cost = 0
            portfolio.total_cost = 0
    
    # åˆ›å»ºäº¤æ˜“è®°å½•
    transaction = Transaction(
        portfolio_id=portfolio.id,
        user_id=user.id,
        transaction_type=transaction_type,
        trade_date=trade_date,
        price=price,
        quantity=quantity,
        amount=amount,
        cost_basis=sell_cost if transaction_type == 'SELL' else 0,
        realized_profit_loss=realized_pnl if transaction_type == 'SELL' else 0,
        notes=notes,
        source=source
    )
    
    db.session.add(transaction)
    db.session.commit()
    
    return jsonify({
        'success': True,
        'transaction': transaction.to_dict(),
        'portfolio': portfolio.to_dict()
    })

@api_bp.route('/transactions/<int:transaction_id>', methods=['PUT'])
def update_transaction(transaction_id):
    """ä¿®æ”¹äº¤æ˜“è®°å½•"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    transaction = Transaction.query.filter_by(id=transaction_id, user_id=user.id).first()
    if not transaction:
        return jsonify({'error': 'äº¤æ˜“è®°å½•ä¸å­˜åœ¨'}), 404
    
    # ç¦æ­¢ä¿®æ”¹è‡ªåŠ¨ç”Ÿæˆçš„äº¤æ˜“è®°å½•ï¼ˆå¦‚ç°é‡‘å˜åŠ¨è®°å½•ï¼‰
    if transaction.source == 'auto':
        return jsonify({'error': 'ä¸èƒ½ä¿®æ”¹è‡ªåŠ¨ç”Ÿæˆçš„äº¤æ˜“è®°å½•'}), 403
    
    data = request.json
    portfolio = Portfolio.query.get(transaction.portfolio_id)
    
    # å…ˆå›æ»šåŸäº¤æ˜“å¯¹æŒä»“çš„å½±å“
    if transaction.transaction_type == 'BUY':
        portfolio.total_cost -= transaction.amount
        portfolio.total_quantity -= transaction.quantity
    else:  # SELL
        sell_cost = portfolio.avg_cost * transaction.quantity
        portfolio.total_cost += sell_cost
        portfolio.total_quantity += transaction.quantity
    
    # æ›´æ–°äº¤æ˜“è®°å½•
    if 'trade_date' in data:
        try:
            transaction.trade_date = datetime.strptime(data['trade_date'], '%Y-%m-%d').date()
        except ValueError:
            return jsonify({'error': 'æ—¥æœŸæ ¼å¼é”™è¯¯'}), 400
    
    new_price = transaction.price
    if 'price' in data:
        try:
            new_price = float(data['price'])
            transaction.price = new_price
        except ValueError:
            return jsonify({'error': 'ä»·æ ¼æ ¼å¼é”™è¯¯'}), 400
    
    if 'quantity' in data:
        try:
            transaction.quantity = float(data['quantity'])
        except ValueError:
            return jsonify({'error': 'æ•°é‡æ ¼å¼é”™è¯¯'}), 400
    elif 'total_amount' in data:
        try:
            total_amount = float(data['total_amount'])
            if new_price <= 0:
                return jsonify({'error': 'ä»·æ ¼å¿…é¡»å¤§äº0'}), 400
            transaction.quantity = total_amount / new_price
        except ValueError:
            return jsonify({'error': 'æ€»é‡‘é¢æ ¼å¼é”™è¯¯'}), 400
    
    if 'notes' in data:
        transaction.notes = data['notes']
    
    # é‡æ–°è®¡ç®—é‡‘é¢
    transaction.amount = transaction.price * transaction.quantity
    
    # åº”ç”¨æ–°äº¤æ˜“å¯¹æŒä»“çš„å½±å“
    if transaction.transaction_type == 'BUY':
        portfolio.total_cost += transaction.amount
        portfolio.total_quantity += transaction.quantity
    else:  # SELL
        if portfolio.total_quantity < transaction.quantity:
            db.session.rollback()
            return jsonify({'error': 'ä¿®æ”¹åæŒä»“æ•°é‡ä¸è¶³'}), 400
        sell_cost = portfolio.avg_cost * transaction.quantity
        portfolio.total_cost -= sell_cost
        portfolio.total_quantity -= transaction.quantity
    
    # é‡æ–°è®¡ç®—å¹³å‡æˆæœ¬
    if portfolio.total_quantity > 0:
        portfolio.avg_cost = portfolio.total_cost / portfolio.total_quantity
    else:
        portfolio.avg_cost = 0
        portfolio.total_cost = 0
    
    db.session.commit()
    
    return jsonify({
        'success': True,
        'transaction': transaction.to_dict(),
        'portfolio': portfolio.to_dict()
    })

@api_bp.route('/transactions/<int:transaction_id>', methods=['DELETE'])
def delete_transaction(transaction_id):
    """åˆ é™¤äº¤æ˜“è®°å½•"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    transaction = Transaction.query.filter_by(id=transaction_id, user_id=user.id).first()
    if not transaction:
        return jsonify({'error': 'äº¤æ˜“è®°å½•ä¸å­˜åœ¨'}), 404
    
    # ç¦æ­¢åˆ é™¤è‡ªåŠ¨ç”Ÿæˆçš„äº¤æ˜“è®°å½•ï¼ˆå¦‚ç°é‡‘å˜åŠ¨è®°å½•ï¼‰
    if transaction.source == 'auto':
        return jsonify({'error': 'ä¸èƒ½åˆ é™¤è‡ªåŠ¨ç”Ÿæˆçš„äº¤æ˜“è®°å½•'}), 403
    
    portfolio = Portfolio.query.get(transaction.portfolio_id)
    
    # å›æ»šäº¤æ˜“å¯¹æŒä»“çš„å½±å“
    if transaction.transaction_type == 'BUY':
        portfolio.total_cost -= transaction.amount
        portfolio.total_quantity -= transaction.quantity
    else:  # SELL
        sell_cost = portfolio.avg_cost * transaction.quantity
        portfolio.total_cost += sell_cost
        portfolio.total_quantity += transaction.quantity
    
    # é‡æ–°è®¡ç®—å¹³å‡æˆæœ¬
    if portfolio.total_quantity > 0:
        portfolio.avg_cost = portfolio.total_cost / portfolio.total_quantity
    else:
        portfolio.avg_cost = 0
        portfolio.total_cost = 0
    
    db.session.delete(transaction)
    db.session.commit()
    
    return jsonify({
        'success': True,
        'portfolio': portfolio.to_dict()
    })

@api_bp.route('/portfolios/<symbol>/transactions', methods=['GET'])
def get_portfolio_transactions(symbol):
    """è·å–æŒ‡å®šæ ‡çš„çš„æ‰€æœ‰äº¤æ˜“è®°å½•"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    asset_type = request.args.get('asset_type', 'STOCK')
    currency = request.args.get('currency')
    
    query_params = {
        'user_id': user.id,
        'symbol': symbol,
        'asset_type': asset_type
    }
    if currency:
        query_params['currency'] = currency
    
    portfolio = Portfolio.query.filter_by(**query_params).first()
    
    if not portfolio:
        return jsonify({'transactions': []})
    
    transactions = Transaction.query.filter_by(
        portfolio_id=portfolio.id,
        user_id=user.id
    ).order_by(Transaction.trade_date.desc()).all()
    
    return jsonify({
        'transactions': [t.to_dict() for t in transactions],
        'portfolio': portfolio.to_dict()
    })

# ==================== Account & Cash Flow APIs ====================

@api_bp.route('/accounts', methods=['GET'])
def get_accounts():
    """è·å–ç”¨æˆ·è´¦æˆ·ä¿¡æ¯"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    accounts = Account.query.filter_by(user_id=user.id).all()
    return jsonify({
        'accounts': [a.to_dict() for a in accounts]
    })

@api_bp.route('/accounts/<currency>', methods=['GET'])
def get_account_by_currency(currency):
    """è·å–æŒ‡å®šå¸ç§çš„è´¦æˆ·ä¿¡æ¯"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    account = get_or_create_account(user.id, currency)
    if not account:
        return jsonify({'error': 'æ— æ³•åˆ›å»ºæˆ–è·å–è´¦æˆ·'}), 500
    
    return jsonify(account.to_dict())

@api_bp.route('/cash-flows', methods=['POST'])
def create_cash_flow():
    """åˆ›å»ºèµ„é‡‘æµæ°´ï¼ˆå…¥é‡‘/å‡ºé‡‘ï¼‰"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    data = request.json
    flow_type = data.get('flow_type')  # DEPOSIT or WITHDRAWAL
    flow_date_str = data.get('flow_date')
    amount = data.get('amount')
    currency = data.get('currency', 'USD')
    notes = data.get('notes', '')
    
    # éªŒè¯å¿…å¡«å­—æ®µ
    if not all([flow_type, flow_date_str, amount]):
        return jsonify({'error': 'ç¼ºå°‘å¿…å¡«å­—æ®µ'}), 400
    
    if flow_type not in ['DEPOSIT', 'WITHDRAWAL']:
        return jsonify({'error': 'æµæ°´ç±»å‹å¿…é¡»æ˜¯ DEPOSIT æˆ– WITHDRAWAL'}), 400
    
    try:
        amount = float(amount)
        if amount <= 0:
            return jsonify({'error': 'é‡‘é¢å¿…é¡»å¤§äº0'}), 400
        flow_date = datetime.strptime(flow_date_str, '%Y-%m-%d').date()
    except ValueError as e:
        return jsonify({'error': f'æ•°æ®æ ¼å¼é”™è¯¯: {str(e)}'}), 400
    
    # æŸ¥æ‰¾æˆ–åˆ›å»ºè´¦æˆ·
    account = get_or_create_account(user.id, currency)
    if not account:
        return jsonify({'error': 'æ— æ³•åˆ›å»ºæˆ–è·å–è´¦æˆ·'}), 500
    
    # æ£€æŸ¥å‡ºé‡‘æ—¶ä½™é¢æ˜¯å¦è¶³å¤Ÿ
    if flow_type == 'WITHDRAWAL':
        # è®¡ç®—å½“å‰æ€»èµ„äº§
        portfolios = Portfolio.query.filter_by(user_id=user.id, currency=currency).all()
        total_assets = sum(p.total_quantity if p.asset_type == 'CASH' else p.total_cost for p in portfolios)
        
        if total_assets < amount:
            return jsonify({'error': f'èµ„äº§ä¸è¶³ï¼Œå½“å‰æ€»èµ„äº§: {total_assets:.2f}'}), 400
    
    # æ›´æ–°è´¦æˆ·ç»Ÿè®¡
    if flow_type == 'DEPOSIT':
        account.total_deposit += amount
        # å…¥é‡‘æ—¶å¢åŠ ç°é‡‘
        success, message = update_cash_balance(
            user_id=user.id,
            currency=currency,
            amount=amount,
            transaction_type='BUY',
            trade_date=flow_date,
            notes=notes or 'å…¥é‡‘'
        )
        if not success:
            db.session.rollback()
            return jsonify({'error': message}), 400
    else:  # WITHDRAWAL
        account.total_withdrawal += amount
        # å‡ºé‡‘æ—¶æ‰£é™¤ç°é‡‘
        success, message = update_cash_balance(
            user_id=user.id,
            currency=currency,
            amount=amount,
            transaction_type='SELL',
            trade_date=flow_date,
            notes=notes or 'å‡ºé‡‘'
        )
        if not success:
            db.session.rollback()
            return jsonify({'error': message}), 400
    
    # åˆ›å»ºèµ„é‡‘æµæ°´è®°å½•
    cash_flow = CashFlow(
        account_id=account.id,
        user_id=user.id,
        flow_type=flow_type,
        flow_date=flow_date,
        amount=amount,
        currency=currency,
        notes=notes,
        source='manual'
    )
    
    db.session.add(cash_flow)
    db.session.commit()
    
    return jsonify({
        'success': True,
        'cash_flow': cash_flow.to_dict(),
        'account': account.to_dict()
    })

@api_bp.route('/cash-flows', methods=['GET'])
def get_cash_flows():
    """è·å–èµ„é‡‘æµæ°´åˆ—è¡¨"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    currency = request.args.get('currency')
    
    query = CashFlow.query.filter_by(user_id=user.id)
    if currency:
        query = query.filter_by(currency=currency)
    
    cash_flows = query.order_by(CashFlow.flow_date.desc()).all()
    
    return jsonify({
        'cash_flows': [cf.to_dict() for cf in cash_flows]
    })

@api_bp.route('/cash-flows/<int:cash_flow_id>', methods=['DELETE'])
def delete_cash_flow(cash_flow_id):
    """åˆ é™¤èµ„é‡‘æµæ°´"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    cash_flow = CashFlow.query.filter_by(id=cash_flow_id, user_id=user.id).first()
    if not cash_flow:
        return jsonify({'error': 'èµ„é‡‘æµæ°´ä¸å­˜åœ¨'}), 404
    
    # ç¦æ­¢åˆ é™¤è‡ªåŠ¨ç”Ÿæˆçš„æµæ°´
    if cash_flow.source == 'auto':
        return jsonify({'error': 'ä¸èƒ½åˆ é™¤è‡ªåŠ¨ç”Ÿæˆçš„èµ„é‡‘æµæ°´'}), 403
    
    # å›æ»šè´¦æˆ·ç»Ÿè®¡
    account = Account.query.get(cash_flow.account_id)
    if cash_flow.flow_type == 'DEPOSIT':
        account.total_deposit -= cash_flow.amount
        # å›æ»šç°é‡‘
        update_cash_balance(
            user_id=user.id,
            currency=cash_flow.currency,
            amount=cash_flow.amount,
            transaction_type='SELL',
            trade_date=cash_flow.flow_date,
            notes=f'åˆ é™¤å…¥é‡‘è®°å½•: {cash_flow.notes}'
        )
    else:
        account.total_withdrawal -= cash_flow.amount
        # å›æ»šç°é‡‘
        update_cash_balance(
            user_id=user.id,
            currency=cash_flow.currency,
            amount=cash_flow.amount,
            transaction_type='BUY',
            trade_date=cash_flow.flow_date,
            notes=f'åˆ é™¤å‡ºé‡‘è®°å½•: {cash_flow.notes}'
        )
    
    db.session.delete(cash_flow)
    db.session.commit()
    
    return jsonify({'success': True})

@api_bp.route('/portfolio-stats', methods=['GET'])
def get_portfolio_stats():
    """è·å–æŠ•èµ„ç»„åˆç»Ÿè®¡ä¿¡æ¯ï¼ˆåŒ…å«å·²å®ç°å’Œæœªå®ç°æ”¶ç›Šï¼‰"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    currency = request.args.get('currency', 'USD')
    
    # è·å–è´¦æˆ·ä¿¡æ¯
    account = get_or_create_account(user.id, currency)
    if not account:
        return jsonify({'error': 'æ— æ³•åˆ›å»ºæˆ–è·å–è´¦æˆ·'}), 500
    
    # è·å–æ‰€æœ‰æŒä»“
    portfolios = Portfolio.query.filter_by(user_id=user.id, currency=currency).all()
    
    # å¼•å…¥ batch_fetcher ç”¨äºè·å–å®æ—¶ä»·æ ¼
    from app.services.data_provider import batch_fetcher
    
    # è®¡ç®—ç»Ÿè®¡æ•°æ®
    total_market_value = 0  # æ€»å¸‚å€¼ï¼ˆåŒ…æ‹¬ç°é‡‘ï¼‰
    total_cost = 0  # æ€»æˆæœ¬ï¼ˆä¸åŒ…æ‹¬ç°é‡‘ï¼‰
    cash_balance = 0  # ç°é‡‘ä½™é¢
    
    # æ”¶é›†ä»·æ ¼è·å–å¤±è´¥çš„é”™è¯¯ä¿¡æ¯
    price_errors = []
    
    for p in portfolios:
        if p.asset_type == 'CASH':
            cash_balance += p.total_quantity
            total_market_value += p.total_quantity
        else:
            total_cost += p.total_cost
            try:
                current_price = batch_fetcher.get_cached_current_price(
                    p.symbol,
                    asset_type=p.asset_type,
                    currency=currency
                )
                
                if current_price:
                    # ä½¿ç”¨å®æ—¶ä»·æ ¼è®¡ç®—å¸‚å€¼
                    current_market_value = float(current_price) * p.total_quantity
                    total_market_value += current_market_value
                else:
                    # è·å–ä»·æ ¼å¤±è´¥ï¼Œè®°å½•é”™è¯¯
                    error_msg = f"æ— æ³•è·å– {p.symbol} çš„å®æ—¶ä»·æ ¼"
                    price_errors.append(error_msg)
                    print(f"âš ï¸ {error_msg}")
            except Exception as e:
                # è·å–ä»·æ ¼å‡ºé”™ï¼Œè®°å½•é”™è¯¯
                error_msg = f"è·å– {p.symbol} å®æ—¶ä»·æ ¼æ—¶å‡ºé”™: {str(e)}"
                price_errors.append(error_msg)
                print(f"âš ï¸ {error_msg}")
    
    # å¦‚æœæœ‰ä»·æ ¼è·å–å¤±è´¥ï¼Œè¿”å›é”™è¯¯
    if price_errors:
        return jsonify({
            'error': 'éƒ¨åˆ†æŒä»“æ— æ³•è·å–å®æ—¶ä»·æ ¼',
            'details': price_errors,
            'failed_count': len(price_errors),
            'total_portfolios': len([p for p in portfolios if p.asset_type != 'CASH'])
        }), 500
    
    # è®¡ç®—æ”¶ç›Š
    net_deposit = account.total_deposit - account.total_withdrawal  # å‡€å…¥é‡‘
    unrealized_pnl = total_market_value - cash_balance - total_cost  # æœªå®ç°ç›ˆäºï¼ˆéç°é‡‘èµ„äº§çš„å¸‚å€¼ - æˆæœ¬ï¼‰
    realized_pnl = account.realized_profit_loss  # å·²å®ç°ç›ˆäº
    total_pnl = realized_pnl + unrealized_pnl  # æ€»ç›ˆäº = å·²å®ç° + æœªå®ç°
    
    # è®¡ç®—æ€»æ”¶ç›Šç‡ï¼šåŸºäºæ€»å¸‚å€¼å’ŒæŠ•èµ„æˆæœ¬ï¼Œç¡®ä¿æœªå®ç°æ”¶ç›Šä¹Ÿè¢«è®¡å…¥
    # æŠ•èµ„æˆæœ¬ = å‡€å…¥é‡‘ï¼ˆå¦‚æœæœ‰è®°å½•ï¼‰æˆ–æ€»æˆæœ¬+ç°é‡‘ä½™é¢ï¼ˆå¦‚æœæ²¡æœ‰å…¥é‡‘è®°å½•ï¼‰
    # æ€»æ”¶ç›Šç‡ = (å½“å‰æ€»å¸‚å€¼ - æŠ•èµ„æˆæœ¬) / æŠ•èµ„æˆæœ¬ * 100 = æ€»ç›ˆäº / æŠ•èµ„æˆæœ¬ * 100
    investment_cost = net_deposit if net_deposit > 0 else (total_cost + cash_balance)
    
    if investment_cost > 0:
        total_return_rate = (total_pnl / investment_cost * 100)
    else:
        # å¦‚æœæŠ•èµ„æˆæœ¬ä¸º0ï¼Œè¯´æ˜æ²¡æœ‰æŠ•èµ„ï¼Œæ€»æ”¶ç›Šç‡ä¸º0
        total_return_rate = 0
    
    return jsonify({
        'currency': currency,
        'net_deposit': net_deposit,  # å‡€å…¥é‡‘
        'total_market_value': total_market_value,  # æ€»å¸‚å€¼
        'cash_balance': cash_balance,  # ç°é‡‘ä½™é¢
        'total_cost': total_cost,  # æ€»æˆæœ¬ï¼ˆä¸å«ç°é‡‘ï¼‰
        'realized_pnl': realized_pnl,  # å·²å®ç°ç›ˆäº
        'unrealized_pnl': unrealized_pnl,  # æœªå®ç°ç›ˆäº
        'total_pnl': total_pnl,  # æ€»ç›ˆäº
        'total_return_rate': total_return_rate,  # æ€»æ”¶ç›Šç‡
        'account': account.to_dict()
    })

# ==================== AI Signal Adoption APIs ====================

@api_bp.route('/ai-signals/<int:signal_id>/adopt', methods=['POST'])
def adopt_ai_signal(signal_id):
    """æ ‡è®°AIå»ºè®®ä¸ºå·²é‡‡çº³ï¼Œå¹¶å…³è”åˆ°ç”¨æˆ·äº¤æ˜“"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    data = request.json
    transaction_id = data.get('transaction_id')
    
    if not transaction_id:
        return jsonify({'error': 'ç¼ºå°‘äº¤æ˜“ID'}), 400
    
    # éªŒè¯ä¿¡å·å­˜åœ¨
    signal = StockTradeSignal.query.get(signal_id)
    if not signal:
        return jsonify({'error': 'ä¿¡å·ä¸å­˜åœ¨'}), 404
    
    # éªŒè¯äº¤æ˜“å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    transaction = Transaction.query.filter_by(
        id=transaction_id,
        user_id=user.id
    ).first()
    if not transaction:
        return jsonify({'error': 'äº¤æ˜“ä¸å­˜åœ¨æˆ–æ— æƒé™'}), 404
    
    # æ›´æ–°ä¿¡å·çŠ¶æ€
    signal.adopted = True
    signal.related_transaction_id = transaction_id
    signal.user_id = user.id
    
    try:
        db.session.commit()
        return jsonify({
            'success': True,
            'signal': signal.to_dict()
        })
    except Exception as e:
        db.session.rollback()
        return jsonify({'error': str(e)}), 500

@api_bp.route('/ai-signals/<int:signal_id>/unadopt', methods=['POST'])
def unadopt_ai_signal(signal_id):
    """å–æ¶ˆæ ‡è®°AIå»ºè®®ä¸ºå·²é‡‡çº³"""
    user = get_user_from_request()
    if not user:
        return jsonify({'error': 'æœªç™»å½•'}), 401
    
    # éªŒè¯ä¿¡å·å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    signal = StockTradeSignal.query.filter_by(
        id=signal_id,
        user_id=user.id
    ).first()
    if not signal:
        return jsonify({'error': 'ä¿¡å·ä¸å­˜åœ¨æˆ–æ— æƒé™'}), 404
    
    # æ›´æ–°ä¿¡å·çŠ¶æ€
    signal.adopted = False
    signal.related_transaction_id = None
    signal.user_id = None
    
    try:
        db.session.commit()
        return jsonify({
            'success': True,
            'signal': signal.to_dict()
        })
    except Exception as e:
        db.session.rollback()
        return jsonify({'error': str(e)}), 500


# ============================================================
# Stock Tracking API Endpoints
# ============================================================

@api_bp.route('/tracking/summary', methods=['GET'])
def tracking_summary():
    """Get tracking portfolio summary."""
    from app.services.tracking_service import tracking_service
    try:
        summary = tracking_service.get_portfolio_summary()
        return jsonify(summary)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@api_bp.route('/tracking/holdings', methods=['GET'])
def tracking_holdings():
    """Get current tracking holdings."""
    from app.services.tracking_service import tracking_service
    try:
        holdings = tracking_service.get_current_holdings()
        return jsonify({'holdings': holdings})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@api_bp.route('/tracking/transactions', methods=['GET'])
def tracking_transactions():
    """Get tracking transaction history."""
    from app.services.tracking_service import tracking_service
    limit = request.args.get('limit', 50, type=int)
    try:
        txns = tracking_service.get_transaction_history(limit=limit)
        return jsonify({'transactions': txns})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@api_bp.route('/tracking/decisions', methods=['GET'])
def tracking_decisions():
    """Get AI decision logs."""
    from app.services.tracking_service import tracking_service
    limit = request.args.get('limit', 30, type=int)
    try:
        logs = tracking_service.get_decision_logs(limit=limit)
        return jsonify({'decisions': logs})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@api_bp.route('/tracking/snapshots', methods=['GET'])
def tracking_snapshots():
    """Get daily portfolio snapshots for charting."""
    from app.services.tracking_service import tracking_service
    start_date = request.args.get('start_date', None)
    try:
        snapshots = tracking_service.get_daily_snapshots(start_date=start_date)
        return jsonify({'snapshots': snapshots})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@api_bp.route('/tracking/benchmark', methods=['GET'])
def tracking_benchmark():
    """Get portfolio vs benchmark comparison data."""
    from app.services.tracking_service import tracking_service
    start_date = request.args.get('start_date', None)
    try:
        data = tracking_service.get_benchmark_comparison(start_date=start_date)
        return jsonify(data)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@api_bp.route('/tracking/refresh-prices', methods=['POST'])
def tracking_refresh_prices():
    """Refresh current prices for all tracked stocks."""
    from app.services.tracking_service import tracking_service
    try:
        result = tracking_service.refresh_prices()
        return jsonify(result)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@api_bp.route('/tracking/run-decision', methods=['POST'])
def tracking_run_decision():
    """Manually trigger an AI decision run (admin action)."""
    from app.services.tracking_service import tracking_service
    model = request.json.get('model', 'gemini-3-flash-preview') if request.is_json else 'gemini-3-flash-preview'
    try:
        result = tracking_service.run_daily_decision(model_name=model)
        return jsonify(result)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@api_bp.route('/tracking/snapshot', methods=['POST'])
def tracking_take_snapshot():
    """Manually take a daily snapshot."""
    from app.services.tracking_service import tracking_service
    try:
        snapshot = tracking_service.take_daily_snapshot()
        return jsonify(snapshot) if snapshot else jsonify({'message': 'Snapshot already exists for today'}), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500
